{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial run to test proteomics data with LDA\n",
    "============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "basedir = '..'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from multifile_feature import FeatureExtractor, SparseFeatureExtractor\n",
    "\n",
    "# living dangerously by suppressing all annoying warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Parse MGF</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to parse the .MGF file and turn it into the count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_mgf(filename, debug=False):\n",
    "    ms1_peakids = []\n",
    "    ms1_peakdata = []\n",
    "    ms2_peakids = []\n",
    "    ms2_peakdata = []\n",
    "    with open(filename, \"r\") as ins:\n",
    "\n",
    "        pep_mass = None\n",
    "        pep_rt = None\n",
    "        pep_charge = np.nan\n",
    "        fragments = []\n",
    "        peak_id = 1\n",
    "        for line in ins:\n",
    "\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue # skip empty line\n",
    "\n",
    "            # split by ' ' or '='\n",
    "            tokens = re.split(' |=', line)\n",
    "            tok = tokens[0].upper()\n",
    "\n",
    "            if tok == 'BEGIN':\n",
    "                continue\n",
    "            elif tok == 'TITLE':\n",
    "                continue\n",
    "            elif tok == 'RTINSECONDS':\n",
    "                pep_rt = float(tokens[1])\n",
    "                ms1_id = peak_id\n",
    "                peak_id += 1            \n",
    "            elif tok == 'PEPMASS':\n",
    "                pep_mass = float(tokens[1])\n",
    "            elif tok == 'CHARGE':\n",
    "                pep_charge = tokens[1]\n",
    "            elif tok == 'END':\n",
    "\n",
    "                if debug:\n",
    "                    print ms1_id, pep_mass, pep_rt, pep_charge\n",
    "                ms1_peakdata.append((ms1_id, np.nan, 1, pep_mass, pep_rt, 0, pep_charge))\n",
    "                ms1_peakids.append(ms1_id)\n",
    "\n",
    "                for ms2_id, ms2_mass, ms2_intensity in fragments:\n",
    "                    if debug:\n",
    "                        print '- %d %f %f' % (ms2_id, ms2_mass, ms2_intensity)\n",
    "                    ms2_peakdata.append((ms2_id, ms1_id, 2, ms2_mass, 0, ms2_intensity, np.nan))\n",
    "                    ms2_peakids.append(ms2_id)\n",
    "                if debug: \n",
    "                    print\n",
    "\n",
    "                # reset for the next line\n",
    "                pep_mass = None\n",
    "                pep_rt = None\n",
    "                pep_charge = np.nan\n",
    "                fragments = []\n",
    "\n",
    "            else: # read the fragments\n",
    "                ms2_mass = float(tok)\n",
    "                ms2_intensity = float(tokens[1])\n",
    "                fragments.append((peak_id, ms2_mass, ms2_intensity))\n",
    "                peak_id += 1\n",
    "\n",
    "    ms1 = pd.DataFrame(ms1_peakdata, index=ms1_peakids, \n",
    "                       columns=['peakID', 'MSnParentPeakID', 'msLevel', 'mz', 'rt', 'intensity', 'charge'])\n",
    "    ms2 = pd.DataFrame(ms2_peakdata, index=ms2_peakids, \n",
    "                       columns=['peakID', 'MSnParentPeakID', 'msLevel', 'mz', 'rt', 'intensity', 'charge'])\n",
    "\n",
    "    return ms1, ms2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filename = 'iPRG2012_small.mgf'\n",
    "filename = 'iPRG2012.mgf'\n",
    "ms1, ms2 = parse_mgf(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peakID</th>\n",
       "      <th>MSnParentPeakID</th>\n",
       "      <th>msLevel</th>\n",
       "      <th>mz</th>\n",
       "      <th>rt</th>\n",
       "      <th>intensity</th>\n",
       "      <th>charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>986.222592</td>\n",
       "      <td>1.850</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1117.290047</td>\n",
       "      <td>2.350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>951.174259</td>\n",
       "      <td>114.576</td>\n",
       "      <td>0</td>\n",
       "      <td>2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>685.120003</td>\n",
       "      <td>115.109</td>\n",
       "      <td>0</td>\n",
       "      <td>2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>818.148264</td>\n",
       "      <td>115.209</td>\n",
       "      <td>0</td>\n",
       "      <td>2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>943.186120</td>\n",
       "      <td>115.309</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1076.713199</td>\n",
       "      <td>115.409</td>\n",
       "      <td>0</td>\n",
       "      <td>2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1084.202678</td>\n",
       "      <td>115.559</td>\n",
       "      <td>0</td>\n",
       "      <td>2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1198.258640</td>\n",
       "      <td>115.709</td>\n",
       "      <td>0</td>\n",
       "      <td>2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1209.246774</td>\n",
       "      <td>115.859</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     peakID  MSnParentPeakID  msLevel           mz       rt  intensity charge\n",
       "1         1              NaN        1   986.222592    1.850          0    NaN\n",
       "6         6              NaN        1  1117.290047    2.350          0    NaN\n",
       "10       10              NaN        1   951.174259  114.576          0     2+\n",
       "60       60              NaN        1   685.120003  115.109          0     2+\n",
       "97       97              NaN        1   818.148264  115.209          0     2+\n",
       "141     141              NaN        1   943.186120  115.309          0    NaN\n",
       "162     162              NaN        1  1076.713199  115.409          0     2+\n",
       "184     184              NaN        1  1084.202678  115.559          0     2+\n",
       "228     228              NaN        1  1198.258640  115.709          0     2+\n",
       "268     268              NaN        1  1209.246774  115.859          0    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17993, 7)\n"
     ]
    }
   ],
   "source": [
    "display(ms1.head(10))\n",
    "print ms1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peakID</th>\n",
       "      <th>MSnParentPeakID</th>\n",
       "      <th>msLevel</th>\n",
       "      <th>mz</th>\n",
       "      <th>rt</th>\n",
       "      <th>intensity</th>\n",
       "      <th>charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>986.331999</td>\n",
       "      <td>0</td>\n",
       "      <td>69.148811</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>989.626160</td>\n",
       "      <td>0</td>\n",
       "      <td>72.000984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>989.716248</td>\n",
       "      <td>0</td>\n",
       "      <td>61.076389</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>989.794898</td>\n",
       "      <td>0</td>\n",
       "      <td>94.243019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1114.994507</td>\n",
       "      <td>0</td>\n",
       "      <td>69.292564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1117.045898</td>\n",
       "      <td>0</td>\n",
       "      <td>61.075764</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1118.765479</td>\n",
       "      <td>0</td>\n",
       "      <td>62.225277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>159.020981</td>\n",
       "      <td>0</td>\n",
       "      <td>9.268942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>213.025406</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>213.038666</td>\n",
       "      <td>0</td>\n",
       "      <td>11.268942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    peakID  MSnParentPeakID  msLevel           mz  rt  intensity  charge\n",
       "2        2                1        2   986.331999   0  69.148811     NaN\n",
       "3        3                1        2   989.626160   0  72.000984     NaN\n",
       "4        4                1        2   989.716248   0  61.076389     NaN\n",
       "5        5                1        2   989.794898   0  94.243019     NaN\n",
       "7        7                6        2  1114.994507   0  69.292564     NaN\n",
       "8        8                6        2  1117.045898   0  61.075764     NaN\n",
       "9        9                6        2  1118.765479   0  62.225277     NaN\n",
       "11      11               10        2   159.020981   0   9.268942     NaN\n",
       "12      12               10        2   213.025406   0  12.000000     NaN\n",
       "13      13               10        2   213.038666   0  11.268942     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682091, 7)\n"
     ]
    }
   ],
   "source": [
    "display(ms2.head(10))\n",
    "print ms2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Feature Extraction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_set = [(ms1, ms2)]\n",
    "fragment_grouping_tol = 7\n",
    "loss_grouping_tol = 15\n",
    "loss_threshold_min_count = 15\n",
    "loss_threshold_max_val = 200\n",
    "scaling_factor = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MS1 dataframe 17993 X 7\n",
      "Loading MS2 dataframe 682091 X 7\n"
     ]
    }
   ],
   "source": [
    "extractor = SparseFeatureExtractor(input_set, fragment_grouping_tol, loss_grouping_tol, \n",
    "                                      loss_threshold_min_count, loss_threshold_max_val,\n",
    "                                     input_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fragments for file 0\n",
      "Total groups=43054\n"
     ]
    }
   ],
   "source": [
    "fragment_q = extractor.make_fragment_queue()\n",
    "fragment_groups = extractor.group_features(fragment_q, extractor.fragment_grouping_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing losses for file 0\n",
      "Total groups=1907\n"
     ]
    }
   ],
   "source": [
    "loss_q = extractor.make_loss_queue()\n",
    "loss_groups = extractor.group_features(loss_q, extractor.loss_grouping_tol, \n",
    "                                       check_threshold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43054 fragment words\n",
      "1907 loss words\n",
      "Initialising sparse matrix 0\n",
      "Populating dataframes\n",
      "Populating dataframe for fragment group 0/43054\n",
      "Populating dataframe for fragment group 100/43054\n",
      "Populating dataframe for fragment group 200/43054\n",
      "Populating dataframe for fragment group 300/43054\n",
      "Populating dataframe for fragment group 400/43054\n",
      "Populating dataframe for fragment group 500/43054\n",
      "Populating dataframe for fragment group 600/43054\n",
      "Populating dataframe for fragment group 700/43054\n",
      "Populating dataframe for fragment group 800/43054\n",
      "Populating dataframe for fragment group 900/43054\n",
      "Populating dataframe for fragment group 1000/43054\n",
      "Populating dataframe for fragment group 1100/43054\n",
      "Populating dataframe for fragment group 1200/43054\n",
      "Populating dataframe for fragment group 1300/43054\n",
      "Populating dataframe for fragment group 1400/43054\n",
      "Populating dataframe for fragment group 1500/43054\n",
      "Populating dataframe for fragment group 1600/43054\n",
      "Populating dataframe for fragment group 1700/43054\n",
      "Populating dataframe for fragment group 1800/43054\n",
      "Populating dataframe for fragment group 1900/43054\n",
      "Populating dataframe for fragment group 2000/43054\n",
      "Populating dataframe for fragment group 2100/43054\n",
      "Populating dataframe for fragment group 2200/43054\n",
      "Populating dataframe for fragment group 2300/43054\n",
      "Populating dataframe for fragment group 2400/43054\n",
      "Populating dataframe for fragment group 2500/43054\n",
      "Populating dataframe for fragment group 2600/43054\n",
      "Populating dataframe for fragment group 2700/43054\n",
      "Populating dataframe for fragment group 2800/43054\n",
      "Populating dataframe for fragment group 2900/43054\n",
      "Populating dataframe for fragment group 3000/43054\n",
      "Populating dataframe for fragment group 3100/43054\n",
      "Populating dataframe for fragment group 3200/43054\n",
      "Populating dataframe for fragment group 3300/43054\n",
      "Populating dataframe for fragment group 3400/43054\n",
      "Populating dataframe for fragment group 3500/43054\n",
      "Populating dataframe for fragment group 3600/43054\n",
      "Populating dataframe for fragment group 3700/43054\n",
      "Populating dataframe for fragment group 3800/43054\n",
      "Populating dataframe for fragment group 3900/43054\n",
      "Populating dataframe for fragment group 4000/43054\n",
      "Populating dataframe for fragment group 4100/43054\n",
      "Populating dataframe for fragment group 4200/43054\n",
      "Populating dataframe for fragment group 4300/43054\n",
      "Populating dataframe for fragment group 4400/43054\n",
      "Populating dataframe for fragment group 4500/43054\n",
      "Populating dataframe for fragment group 4600/43054\n",
      "Populating dataframe for fragment group 4700/43054\n",
      "Populating dataframe for fragment group 4800/43054\n",
      "Populating dataframe for fragment group 4900/43054\n",
      "Populating dataframe for fragment group 5000/43054\n",
      "Populating dataframe for fragment group 5100/43054\n",
      "Populating dataframe for fragment group 5200/43054\n",
      "Populating dataframe for fragment group 5300/43054\n",
      "Populating dataframe for fragment group 5400/43054\n",
      "Populating dataframe for fragment group 5500/43054\n",
      "Populating dataframe for fragment group 5600/43054\n",
      "Populating dataframe for fragment group 5700/43054\n",
      "Populating dataframe for fragment group 5800/43054\n",
      "Populating dataframe for fragment group 5900/43054\n",
      "Populating dataframe for fragment group 6000/43054\n",
      "Populating dataframe for fragment group 6100/43054\n",
      "Populating dataframe for fragment group 6200/43054\n",
      "Populating dataframe for fragment group 6300/43054\n",
      "Populating dataframe for fragment group 6400/43054\n",
      "Populating dataframe for fragment group 6500/43054\n",
      "Populating dataframe for fragment group 6600/43054\n",
      "Populating dataframe for fragment group 6700/43054\n",
      "Populating dataframe for fragment group 6800/43054\n",
      "Populating dataframe for fragment group 6900/43054\n",
      "Populating dataframe for fragment group 7000/43054\n",
      "Populating dataframe for fragment group 7100/43054\n",
      "Populating dataframe for fragment group 7200/43054\n",
      "Populating dataframe for fragment group 7300/43054\n",
      "Populating dataframe for fragment group 7400/43054\n",
      "Populating dataframe for fragment group 7500/43054\n",
      "Populating dataframe for fragment group 7600/43054\n",
      "Populating dataframe for fragment group 7700/43054\n",
      "Populating dataframe for fragment group 7800/43054\n",
      "Populating dataframe for fragment group 7900/43054\n",
      "Populating dataframe for fragment group 8000/43054\n",
      "Populating dataframe for fragment group 8100/43054\n",
      "Populating dataframe for fragment group 8200/43054\n",
      "Populating dataframe for fragment group 8300/43054\n",
      "Populating dataframe for fragment group 8400/43054\n",
      "Populating dataframe for fragment group 8500/43054\n",
      "Populating dataframe for fragment group 8600/43054\n",
      "Populating dataframe for fragment group 8700/43054\n",
      "Populating dataframe for fragment group 8800/43054\n",
      "Populating dataframe for fragment group 8900/43054\n",
      "Populating dataframe for fragment group 9000/43054\n",
      "Populating dataframe for fragment group 9100/43054\n",
      "Populating dataframe for fragment group 9200/43054\n",
      "Populating dataframe for fragment group 9300/43054\n",
      "Populating dataframe for fragment group 9400/43054\n",
      "Populating dataframe for fragment group 9500/43054\n",
      "Populating dataframe for fragment group 9600/43054\n",
      "Populating dataframe for fragment group 9700/43054\n",
      "Populating dataframe for fragment group 9800/43054\n",
      "Populating dataframe for fragment group 9900/43054\n",
      "Populating dataframe for fragment group 10000/43054\n",
      "Populating dataframe for fragment group 10100/43054\n",
      "Populating dataframe for fragment group 10200/43054\n",
      "Populating dataframe for fragment group 10300/43054\n",
      "Populating dataframe for fragment group 10400/43054\n",
      "Populating dataframe for fragment group 10500/43054\n",
      "Populating dataframe for fragment group 10600/43054\n",
      "Populating dataframe for fragment group 10700/43054\n",
      "Populating dataframe for fragment group 10800/43054\n",
      "Populating dataframe for fragment group 10900/43054\n",
      "Populating dataframe for fragment group 11000/43054\n",
      "Populating dataframe for fragment group 11100/43054\n",
      "Populating dataframe for fragment group 11200/43054\n",
      "Populating dataframe for fragment group 11300/43054\n",
      "Populating dataframe for fragment group 11400/43054\n",
      "Populating dataframe for fragment group 11500/43054\n",
      "Populating dataframe for fragment group 11600/43054\n",
      "Populating dataframe for fragment group 11700/43054\n",
      "Populating dataframe for fragment group 11800/43054\n",
      "Populating dataframe for fragment group 11900/43054\n",
      "Populating dataframe for fragment group 12000/43054\n",
      "Populating dataframe for fragment group 12100/43054\n",
      "Populating dataframe for fragment group 12200/43054\n",
      "Populating dataframe for fragment group 12300/43054\n",
      "Populating dataframe for fragment group 12400/43054\n",
      "Populating dataframe for fragment group 12500/43054\n",
      "Populating dataframe for fragment group 12600/43054\n",
      "Populating dataframe for fragment group 12700/43054\n",
      "Populating dataframe for fragment group 12800/43054\n",
      "Populating dataframe for fragment group 12900/43054\n",
      "Populating dataframe for fragment group 13000/43054\n",
      "Populating dataframe for fragment group 13100/43054\n",
      "Populating dataframe for fragment group 13200/43054\n",
      "Populating dataframe for fragment group 13300/43054\n",
      "Populating dataframe for fragment group 13400/43054\n",
      "Populating dataframe for fragment group 13500/43054\n",
      "Populating dataframe for fragment group 13600/43054\n",
      "Populating dataframe for fragment group 13700/43054\n",
      "Populating dataframe for fragment group 13800/43054\n",
      "Populating dataframe for fragment group 13900/43054\n",
      "Populating dataframe for fragment group 14000/43054\n",
      "Populating dataframe for fragment group 14100/43054\n",
      "Populating dataframe for fragment group 14200/43054\n",
      "Populating dataframe for fragment group 14300/43054\n",
      "Populating dataframe for fragment group 14400/43054\n",
      "Populating dataframe for fragment group 14500/43054\n",
      "Populating dataframe for fragment group 14600/43054\n",
      "Populating dataframe for fragment group 14700/43054\n",
      "Populating dataframe for fragment group 14800/43054\n",
      "Populating dataframe for fragment group 14900/43054\n",
      "Populating dataframe for fragment group 15000/43054\n",
      "Populating dataframe for fragment group 15100/43054\n",
      "Populating dataframe for fragment group 15200/43054\n",
      "Populating dataframe for fragment group 15300/43054\n",
      "Populating dataframe for fragment group 15400/43054\n",
      "Populating dataframe for fragment group 15500/43054\n",
      "Populating dataframe for fragment group 15600/43054\n",
      "Populating dataframe for fragment group 15700/43054\n",
      "Populating dataframe for fragment group 15800/43054\n",
      "Populating dataframe for fragment group 15900/43054\n",
      "Populating dataframe for fragment group 16000/43054\n",
      "Populating dataframe for fragment group 16100/43054\n",
      "Populating dataframe for fragment group 16200/43054\n",
      "Populating dataframe for fragment group 16300/43054\n",
      "Populating dataframe for fragment group 16400/43054\n",
      "Populating dataframe for fragment group 16500/43054\n",
      "Populating dataframe for fragment group 16600/43054\n",
      "Populating dataframe for fragment group 16700/43054\n",
      "Populating dataframe for fragment group 16800/43054\n",
      "Populating dataframe for fragment group 16900/43054\n",
      "Populating dataframe for fragment group 17000/43054\n",
      "Populating dataframe for fragment group 17100/43054\n",
      "Populating dataframe for fragment group 17200/43054\n",
      "Populating dataframe for fragment group 17300/43054\n",
      "Populating dataframe for fragment group 17400/43054\n",
      "Populating dataframe for fragment group 17500/43054\n",
      "Populating dataframe for fragment group 17600/43054\n",
      "Populating dataframe for fragment group 17700/43054\n",
      "Populating dataframe for fragment group 17800/43054\n",
      "Populating dataframe for fragment group 17900/43054\n",
      "Populating dataframe for fragment group 18000/43054\n",
      "Populating dataframe for fragment group 18100/43054\n",
      "Populating dataframe for fragment group 18200/43054\n",
      "Populating dataframe for fragment group 18300/43054\n",
      "Populating dataframe for fragment group 18400/43054\n",
      "Populating dataframe for fragment group 18500/43054\n",
      "Populating dataframe for fragment group 18600/43054\n",
      "Populating dataframe for fragment group 18700/43054\n",
      "Populating dataframe for fragment group 18800/43054\n",
      "Populating dataframe for fragment group 18900/43054\n",
      "Populating dataframe for fragment group 19000/43054\n",
      "Populating dataframe for fragment group 19100/43054\n",
      "Populating dataframe for fragment group 19200/43054\n",
      "Populating dataframe for fragment group 19300/43054\n",
      "Populating dataframe for fragment group 19400/43054\n",
      "Populating dataframe for fragment group 19500/43054\n",
      "Populating dataframe for fragment group 19600/43054\n",
      "Populating dataframe for fragment group 19700/43054\n",
      "Populating dataframe for fragment group 19800/43054\n",
      "Populating dataframe for fragment group 19900/43054\n",
      "Populating dataframe for fragment group 20000/43054\n",
      "Populating dataframe for fragment group 20100/43054\n",
      "Populating dataframe for fragment group 20200/43054\n",
      "Populating dataframe for fragment group 20300/43054\n",
      "Populating dataframe for fragment group 20400/43054\n",
      "Populating dataframe for fragment group 20500/43054\n",
      "Populating dataframe for fragment group 20600/43054\n",
      "Populating dataframe for fragment group 20700/43054\n",
      "Populating dataframe for fragment group 20800/43054\n",
      "Populating dataframe for fragment group 20900/43054\n",
      "Populating dataframe for fragment group 21000/43054\n",
      "Populating dataframe for fragment group 21100/43054\n",
      "Populating dataframe for fragment group 21200/43054\n",
      "Populating dataframe for fragment group 21300/43054\n",
      "Populating dataframe for fragment group 21400/43054\n",
      "Populating dataframe for fragment group 21500/43054\n",
      "Populating dataframe for fragment group 21600/43054\n",
      "Populating dataframe for fragment group 21700/43054\n",
      "Populating dataframe for fragment group 21800/43054\n",
      "Populating dataframe for fragment group 21900/43054\n",
      "Populating dataframe for fragment group 22000/43054\n",
      "Populating dataframe for fragment group 22100/43054\n",
      "Populating dataframe for fragment group 22200/43054\n",
      "Populating dataframe for fragment group 22300/43054\n",
      "Populating dataframe for fragment group 22400/43054\n",
      "Populating dataframe for fragment group 22500/43054\n",
      "Populating dataframe for fragment group 22600/43054\n",
      "Populating dataframe for fragment group 22700/43054\n",
      "Populating dataframe for fragment group 22800/43054\n",
      "Populating dataframe for fragment group 22900/43054\n",
      "Populating dataframe for fragment group 23000/43054\n",
      "Populating dataframe for fragment group 23100/43054\n",
      "Populating dataframe for fragment group 23200/43054\n",
      "Populating dataframe for fragment group 23300/43054\n",
      "Populating dataframe for fragment group 23400/43054\n",
      "Populating dataframe for fragment group 23500/43054\n",
      "Populating dataframe for fragment group 23600/43054\n",
      "Populating dataframe for fragment group 23700/43054\n",
      "Populating dataframe for fragment group 23800/43054\n",
      "Populating dataframe for fragment group 23900/43054\n",
      "Populating dataframe for fragment group 24000/43054\n",
      "Populating dataframe for fragment group 24100/43054\n",
      "Populating dataframe for fragment group 24200/43054\n",
      "Populating dataframe for fragment group 24300/43054\n",
      "Populating dataframe for fragment group 24400/43054\n",
      "Populating dataframe for fragment group 24500/43054\n",
      "Populating dataframe for fragment group 24600/43054\n",
      "Populating dataframe for fragment group 24700/43054\n",
      "Populating dataframe for fragment group 24800/43054\n",
      "Populating dataframe for fragment group 24900/43054\n",
      "Populating dataframe for fragment group 25000/43054\n",
      "Populating dataframe for fragment group 25100/43054\n",
      "Populating dataframe for fragment group 25200/43054\n",
      "Populating dataframe for fragment group 25300/43054\n",
      "Populating dataframe for fragment group 25400/43054\n",
      "Populating dataframe for fragment group 25500/43054\n",
      "Populating dataframe for fragment group 25600/43054\n",
      "Populating dataframe for fragment group 25700/43054\n",
      "Populating dataframe for fragment group 25800/43054\n",
      "Populating dataframe for fragment group 25900/43054\n",
      "Populating dataframe for fragment group 26000/43054\n",
      "Populating dataframe for fragment group 26100/43054\n",
      "Populating dataframe for fragment group 26200/43054\n",
      "Populating dataframe for fragment group 26300/43054\n",
      "Populating dataframe for fragment group 26400/43054\n",
      "Populating dataframe for fragment group 26500/43054\n",
      "Populating dataframe for fragment group 26600/43054\n",
      "Populating dataframe for fragment group 26700/43054\n",
      "Populating dataframe for fragment group 26800/43054\n",
      "Populating dataframe for fragment group 26900/43054\n",
      "Populating dataframe for fragment group 27000/43054\n",
      "Populating dataframe for fragment group 27100/43054\n",
      "Populating dataframe for fragment group 27200/43054\n",
      "Populating dataframe for fragment group 27300/43054\n",
      "Populating dataframe for fragment group 27400/43054\n",
      "Populating dataframe for fragment group 27500/43054\n",
      "Populating dataframe for fragment group 27600/43054\n",
      "Populating dataframe for fragment group 27700/43054\n",
      "Populating dataframe for fragment group 27800/43054\n",
      "Populating dataframe for fragment group 27900/43054\n",
      "Populating dataframe for fragment group 28000/43054\n",
      "Populating dataframe for fragment group 28100/43054\n",
      "Populating dataframe for fragment group 28200/43054\n",
      "Populating dataframe for fragment group 28300/43054\n",
      "Populating dataframe for fragment group 28400/43054\n",
      "Populating dataframe for fragment group 28500/43054\n",
      "Populating dataframe for fragment group 28600/43054\n",
      "Populating dataframe for fragment group 28700/43054\n",
      "Populating dataframe for fragment group 28800/43054\n",
      "Populating dataframe for fragment group 28900/43054\n",
      "Populating dataframe for fragment group 29000/43054\n",
      "Populating dataframe for fragment group 29100/43054\n",
      "Populating dataframe for fragment group 29200/43054\n",
      "Populating dataframe for fragment group 29300/43054\n",
      "Populating dataframe for fragment group 29400/43054\n",
      "Populating dataframe for fragment group 29500/43054\n",
      "Populating dataframe for fragment group 29600/43054\n",
      "Populating dataframe for fragment group 29700/43054\n",
      "Populating dataframe for fragment group 29800/43054\n",
      "Populating dataframe for fragment group 29900/43054\n",
      "Populating dataframe for fragment group 30000/43054\n",
      "Populating dataframe for fragment group 30100/43054\n",
      "Populating dataframe for fragment group 30200/43054\n",
      "Populating dataframe for fragment group 30300/43054\n",
      "Populating dataframe for fragment group 30400/43054\n",
      "Populating dataframe for fragment group 30500/43054\n",
      "Populating dataframe for fragment group 30600/43054\n",
      "Populating dataframe for fragment group 30700/43054\n",
      "Populating dataframe for fragment group 30800/43054\n",
      "Populating dataframe for fragment group 30900/43054\n",
      "Populating dataframe for fragment group 31000/43054\n",
      "Populating dataframe for fragment group 31100/43054\n",
      "Populating dataframe for fragment group 31200/43054\n",
      "Populating dataframe for fragment group 31300/43054\n",
      "Populating dataframe for fragment group 31400/43054\n",
      "Populating dataframe for fragment group 31500/43054\n",
      "Populating dataframe for fragment group 31600/43054\n",
      "Populating dataframe for fragment group 31700/43054\n",
      "Populating dataframe for fragment group 31800/43054\n",
      "Populating dataframe for fragment group 31900/43054\n",
      "Populating dataframe for fragment group 32000/43054\n",
      "Populating dataframe for fragment group 32100/43054\n",
      "Populating dataframe for fragment group 32200/43054\n",
      "Populating dataframe for fragment group 32300/43054\n",
      "Populating dataframe for fragment group 32400/43054\n",
      "Populating dataframe for fragment group 32500/43054\n",
      "Populating dataframe for fragment group 32600/43054\n",
      "Populating dataframe for fragment group 32700/43054\n",
      "Populating dataframe for fragment group 32800/43054\n",
      "Populating dataframe for fragment group 32900/43054\n",
      "Populating dataframe for fragment group 33000/43054\n",
      "Populating dataframe for fragment group 33100/43054\n",
      "Populating dataframe for fragment group 33200/43054\n",
      "Populating dataframe for fragment group 33300/43054\n",
      "Populating dataframe for fragment group 33400/43054\n",
      "Populating dataframe for fragment group 33500/43054\n",
      "Populating dataframe for fragment group 33600/43054\n",
      "Populating dataframe for fragment group 33700/43054\n",
      "Populating dataframe for fragment group 33800/43054\n",
      "Populating dataframe for fragment group 33900/43054\n",
      "Populating dataframe for fragment group 34000/43054\n",
      "Populating dataframe for fragment group 34100/43054\n",
      "Populating dataframe for fragment group 34200/43054\n",
      "Populating dataframe for fragment group 34300/43054\n",
      "Populating dataframe for fragment group 34400/43054\n",
      "Populating dataframe for fragment group 34500/43054\n",
      "Populating dataframe for fragment group 34600/43054\n",
      "Populating dataframe for fragment group 34700/43054\n",
      "Populating dataframe for fragment group 34800/43054\n",
      "Populating dataframe for fragment group 34900/43054\n",
      "Populating dataframe for fragment group 35000/43054\n",
      "Populating dataframe for fragment group 35100/43054\n",
      "Populating dataframe for fragment group 35200/43054\n",
      "Populating dataframe for fragment group 35300/43054\n",
      "Populating dataframe for fragment group 35400/43054\n",
      "Populating dataframe for fragment group 35500/43054\n",
      "Populating dataframe for fragment group 35600/43054\n",
      "Populating dataframe for fragment group 35700/43054\n",
      "Populating dataframe for fragment group 35800/43054\n",
      "Populating dataframe for fragment group 35900/43054\n",
      "Populating dataframe for fragment group 36000/43054\n",
      "Populating dataframe for fragment group 36100/43054\n",
      "Populating dataframe for fragment group 36200/43054\n",
      "Populating dataframe for fragment group 36300/43054\n",
      "Populating dataframe for fragment group 36400/43054\n",
      "Populating dataframe for fragment group 36500/43054\n",
      "Populating dataframe for fragment group 36600/43054\n",
      "Populating dataframe for fragment group 36700/43054\n",
      "Populating dataframe for fragment group 36800/43054\n",
      "Populating dataframe for fragment group 36900/43054\n",
      "Populating dataframe for fragment group 37000/43054\n",
      "Populating dataframe for fragment group 37100/43054\n",
      "Populating dataframe for fragment group 37200/43054\n",
      "Populating dataframe for fragment group 37300/43054\n",
      "Populating dataframe for fragment group 37400/43054\n",
      "Populating dataframe for fragment group 37500/43054\n",
      "Populating dataframe for fragment group 37600/43054\n",
      "Populating dataframe for fragment group 37700/43054\n",
      "Populating dataframe for fragment group 37800/43054\n",
      "Populating dataframe for fragment group 37900/43054\n",
      "Populating dataframe for fragment group 38000/43054\n",
      "Populating dataframe for fragment group 38100/43054\n",
      "Populating dataframe for fragment group 38200/43054\n",
      "Populating dataframe for fragment group 38300/43054\n",
      "Populating dataframe for fragment group 38400/43054\n",
      "Populating dataframe for fragment group 38500/43054\n",
      "Populating dataframe for fragment group 38600/43054\n",
      "Populating dataframe for fragment group 38700/43054\n",
      "Populating dataframe for fragment group 38800/43054\n",
      "Populating dataframe for fragment group 38900/43054\n",
      "Populating dataframe for fragment group 39000/43054\n",
      "Populating dataframe for fragment group 39100/43054\n",
      "Populating dataframe for fragment group 39200/43054\n",
      "Populating dataframe for fragment group 39300/43054\n",
      "Populating dataframe for fragment group 39400/43054\n",
      "Populating dataframe for fragment group 39500/43054\n",
      "Populating dataframe for fragment group 39600/43054\n",
      "Populating dataframe for fragment group 39700/43054\n",
      "Populating dataframe for fragment group 39800/43054\n",
      "Populating dataframe for fragment group 39900/43054\n",
      "Populating dataframe for fragment group 40000/43054\n",
      "Populating dataframe for fragment group 40100/43054\n",
      "Populating dataframe for fragment group 40200/43054\n",
      "Populating dataframe for fragment group 40300/43054\n",
      "Populating dataframe for fragment group 40400/43054\n",
      "Populating dataframe for fragment group 40500/43054\n",
      "Populating dataframe for fragment group 40600/43054\n",
      "Populating dataframe for fragment group 40700/43054\n",
      "Populating dataframe for fragment group 40800/43054\n",
      "Populating dataframe for fragment group 40900/43054\n",
      "Populating dataframe for fragment group 41000/43054\n",
      "Populating dataframe for fragment group 41100/43054\n",
      "Populating dataframe for fragment group 41200/43054\n",
      "Populating dataframe for fragment group 41300/43054\n",
      "Populating dataframe for fragment group 41400/43054\n",
      "Populating dataframe for fragment group 41500/43054\n",
      "Populating dataframe for fragment group 41600/43054\n",
      "Populating dataframe for fragment group 41700/43054\n",
      "Populating dataframe for fragment group 41800/43054\n",
      "Populating dataframe for fragment group 41900/43054\n",
      "Populating dataframe for fragment group 42000/43054\n",
      "Populating dataframe for fragment group 42100/43054\n",
      "Populating dataframe for fragment group 42200/43054\n",
      "Populating dataframe for fragment group 42300/43054\n",
      "Populating dataframe for fragment group 42400/43054\n",
      "Populating dataframe for fragment group 42500/43054\n",
      "Populating dataframe for fragment group 42600/43054\n",
      "Populating dataframe for fragment group 42700/43054\n",
      "Populating dataframe for fragment group 42800/43054\n",
      "Populating dataframe for fragment group 42900/43054\n",
      "Populating dataframe for fragment group 43000/43054\n",
      "Populating dataframe for loss group 0/1907\n",
      "Populating dataframe for loss group 100/1907\n",
      "Populating dataframe for loss group 200/1907\n",
      "Populating dataframe for loss group 300/1907\n",
      "Populating dataframe for loss group 400/1907\n",
      "Populating dataframe for loss group 500/1907\n",
      "Populating dataframe for loss group 600/1907\n",
      "Populating dataframe for loss group 700/1907\n",
      "Populating dataframe for loss group 800/1907\n",
      "Populating dataframe for loss group 900/1907\n",
      "Populating dataframe for loss group 1000/1907\n",
      "Populating dataframe for loss group 1100/1907\n",
      "Populating dataframe for loss group 1200/1907\n",
      "Populating dataframe for loss group 1300/1907\n",
      "Populating dataframe for loss group 1400/1907\n",
      "Populating dataframe for loss group 1500/1907\n",
      "Populating dataframe for loss group 1600/1907\n",
      "Populating dataframe for loss group 1700/1907\n",
      "Populating dataframe for loss group 1800/1907\n",
      "Populating dataframe for loss group 1900/1907\n",
      "Normalising dataframe 0\n",
      "file 0 normalising\n",
      "file 0 normalised csc shape (17993, 44961)\n",
      "file 0 converting csc to sparse dataframe\n"
     ]
    }
   ],
   "source": [
    "extractor.create_counts(fragment_groups, loss_groups, scaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df, vocab, ms1, ms2 = extractor.get_entry(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>a. Run LDA</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been loaded by performing either step 1(a) or 1(b), we're now ready to run LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms2lda = Ms2Lda(df, vocab, ms1, ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### all the parameters you need to specify to run LDA ###\n",
    "\n",
    "n_topics = 300 # 300 - 400 topics from cross-validation\n",
    "n_samples = 10 # 100 is probably okay for testing. For manuscript, use > 500-1000.\n",
    "n_burn = 0 # if 0 then we only use the last sample\n",
    "n_thin = 1 # every n-th sample to use for averaging after burn-in. Ignored if n_burn = 0\n",
    "alpha = 50.0/n_topics # hyper-parameter for document-topic distributions\n",
    "beta = 0.1 # hyper-parameter for topic-word distributions\n",
    "\n",
    "ms2lda.run_lda(n_topics, n_samples, n_burn, n_thin, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leave the message parameter out if nothing to say\n",
    "ms2lda.save_project('results/analysis.project', message=\"First try\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**resume project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from lda_for_fragments import Ms2Lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda = Ms2Lda.resume_from('results/analysis.project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda.do_thresholding(th_doc_topic=0.05, th_topic_word=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms2lda.print_topic_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms2lda.plot_lda_fragments(interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

str(runif(nrow*ncol))
matrix(runif(nrow*ncol), nrow, ncol)
?matrix
rest <- matrix(runif(nrow*ncol), nrow, ncol)
pattern <- mvrnorm(n=10, mu, sigma)
pattern
rest
cbind(pattern, rest)
combined <- cbind(pattern, rest)
heatmap(combined)
mu <- rep(5, 4)
sigma <- matrix(c(1, 1, 1, 1, 1, 1, 1, 1), 4, 4)
pattern2 <- mvrnorm(n=10, mu, sigma)
rest2 <- matrix(runif(nrow*ncol), nrow, ncol)
combined2 <- cbind(pattern2, rest2)
all <- rbind(combined, combined2)
heatmap(all)
mypca <- prcomp(all)
print(mypca)
plot(mycpa, type="1!")
plot(mycpa, type="1")
plot(mypca, type="1")
mypca <- prcomp(all)su
summary(mypca)
> screeplot(wine.pca, type="lines")
screeplot(mypca, type="lines")
require(MASS)
?mvrnorm
mu1 <- rep(0, 4)
sigma1 <- matrix(rep(1, 16), 4, 4)
mu1
sigma1
mvrnorm(10, mu1, sigma1)
sigma1 <- matrix(rep(10, 16), 4, 4)
mvrnorm(10, mu1, sigma1)
sigma1 <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16), 4, 4)
mvrnorm(10, mu1, sigma1)
seq(1, 16)
seq(1, 16, by=2)
sigma1 <- seq(1, 16)
mvrnorm(10, mu1, sigma1)
sigma1 <- matrix(seq(1, 16), 4, 4)
mvrnorm(10, mu1, sigma1)
mvrnorm(10, mu1, sigma1)
data1 <- mvrnorm(10, mu1, sigma1)
runif
matrix(runif(10*6), 10, 6)
noise1 <- matrix(runif(10*6), 10, 6)
cbind(data1, noise1)
group1 <- cbind(data1, noise1)
sigma2 <- matrix(seq(1, 32, by=2), 4, 4)
data2 <- mvrnorm(10, mu1, sigma1)
noise2 <- matrix(runif(10*6), 10, 6)
group2 <- cbind(data2, noise2)
groups <- rbind(group1, group2)
heatmap(groups)
library(car)
library("car")
install.packages(car)
install.packages("car")
library(car)
scatterplotMatrix(groups)
groups
plot(groups[, 1], groups[, 2])
scatterplotMatrix(groups)
plot(groups[, 1], groups[, 2])
scatterplotMatrix(groups)
plot(groups[, 1], groups[, 3])
scale(groups)
sgroups <- scale(groups)
heatmap(sgroups)
heatmap(groups)
heatmap(sgroups)
sapply(sgroups, mean)
sgroups <- as.data.frame(scale(groups))
sgroups
sgroups$V1
sapply(sgroups, mean)
sapply(sgroups, sd)
pca <- prcomp(sgroups)
summary(pca)
pca$sdev
sum((pca$sdev)^2)
screeplot(pca)
?screeplot
screeplot(pca, type="lines")
pca$sdev^2
(pca$sdev)^2
pca$rotation
pca$rotation[, 1]
sum(pca$rotation[, 1]^2)
pca$x
pca$x[, 1]
plot(pca$x[, 1], pca$[x, 2])
plot(pca$x[, 1], pca$[x, 2])
pca$x[, 1]
pca$x[, 2]
pca$x[, 2]
pc1 <- pca$x[, 1]
pc2 <- pca$x[, 2]
plot(pc1, pc2)
text(pc1, pc2, groups$V1, cex=0.7, pos=4, col="red")
groups
text(pc1, pc2, sgroups$V1, cex=0.7, pos=4, col="red")
install.packages(c("rJava"))
install.packages(c("rJava"))
R CMD javareconf
install.packages(c("rJava"))
install.packages(c("rJava"))
setwd("~/git/metabolomics_tools/multifile_lda/R")
setwd("~/git/metabolomics_tools/multifile_lda/R")
config_filename <- "config.yml"
config <- yaml.load_file(config_filename)
create_peak_method <- config$create_peak_method
library(xcms)       # Load XCMS
library(RMassBank)  # Load RMassBank
library(gtools)     # Used for natural sorting
library(yaml)       # Used for reading configuration file
config <- yaml.load_file(config_filename)
create_peak_method <- config$create_peak_method
if (create_peak_method == 1) {
print("Running create_peak_method #1")
source('runCreatePeakMethod1.R')
peaks <- run_create_peak_method_1(config)
} else if (create_peak_method == 2) {
print("Running create_peak_method #2")
source('runCreatePeakMethod2.R')
peaks <- run_create_peak_method_2(config)
} else if (create_peak_method == 3) {
print("Running create_peak_method #3")
source('runCreatePeakMethod3.R')
peaks <- run_create_peak_method_3(config)
}
source('createPeakList.R')
results <- create_peaklist(peaks, config)
ms1 <- results$ms1
ms2 <- results$ms2
source('extractFragmentFeatures.R')
results <- extract_ms2_fragment_df(ms1, ms2, config)
fragment_df <- results$fragment_df
ms2 <- results$ms2
source('extractFragmentFeatures.R')
results <- extract_ms2_fragment_df(ms1, ms2, config)
all_ms1
ms1
length(ms1)
ms1[[1]]
file_ms1 <- ms1[[1]]
file_ms2 <- ms2[[1]]
ms2_masses <- file_ms2$mz
ms2_masses
parent_ids <- file_ms2$MSnParentPeakID
parent_ids
matches <- match(as.character(parent_ids), file_ms1.names)
file_ms1.names
file_ms1.names <- as.character(file_ms1$peakID) # set row names on ms1 dataframe
file_ms2.names <- as.character(file_ms2$peakID) # set row names on ms2 dataframe
file_ms1.names
matches <- match(as.character(parent_ids), file_ms1.names)
matches
parent_masses <- file_ms1[matches, 5] # column 5 is the mz
parent_masses
losses <- parent_masses - ms2_masses
losses
View(file_ms2)
file_ms2[, "loss"] <- losses
View(file_ms2)
all_ms2 <- ms2
for (i in 1:length(all_ms2)) {
file_ms1 <- all_ms1[[i]]
file_ms2 <- all_ms2[[i]]
file_ms1.names <- as.character(file_ms1$peakID) # set row names on ms1 dataframe
file_ms2.names <- as.character(file_ms2$peakID) # set row names on ms2 dataframe
# compute the difference between each fragment peak to its parent
ms2_masses <- file_ms2$mz
parent_ids <- file_ms2$MSnParentPeakID
matches <- match(as.character(parent_ids), file_ms1.names)
parent_masses <- file_ms1[matches, 5] # column 5 is the mz
losses <- parent_masses - ms2_masses
file_ms2[, "loss"] <- losses
}
all_ms1 <- ms2
all_ms1 <- ms1
for (i in 1:length(all_ms2)) {
file_ms1 <- all_ms1[[i]]
file_ms2 <- all_ms2[[i]]
file_ms1.names <- as.character(file_ms1$peakID) # set row names on ms1 dataframe
file_ms2.names <- as.character(file_ms2$peakID) # set row names on ms2 dataframe
# compute the difference between each fragment peak to its parent
ms2_masses <- file_ms2$mz
parent_ids <- file_ms2$MSnParentPeakID
matches <- match(as.character(parent_ids), file_ms1.names)
parent_masses <- file_ms1[matches, 5] # column 5 is the mz
losses <- parent_masses - ms2_masses
file_ms2[, "loss"] <- losses
}
View(all_ms1[[1]])
View(all_ms2[[1]])
for (i in 1:length(all_ms2)) {
file_ms1 <- all_ms1[[i]]
file_ms2 <- all_ms2[[i]]
file_ms1.names <- as.character(file_ms1$peakID) # set row names on ms1 dataframe
file_ms2.names <- as.character(file_ms2$peakID) # set row names on ms2 dataframe
# compute the difference between each fragment peak to its parent
ms2_masses <- file_ms2$mz
parent_ids <- file_ms2$MSnParentPeakID
matches <- match(as.character(parent_ids), file_ms1.names)
parent_masses <- file_ms1[matches, 5] # column 5 is the mz
losses <- parent_masses - ms2_masses
file_ms2[, "loss"] <- losses
all_ms2[[i]] <- file_ms2
}
View(all_ms2[[1]])
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(mz)), ]
View(combined_ms2)
results <- extract_ms2_fragment_df(ms1, ms2, config)
fragment_df <- results$fragment_df
ms2 <- results$ms2
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
all_ms1 <- ms1
all_ms2 <- ms2
stopifnot(length(all_ms1)==length(all_ms2))
print("Constructing common loss bins shared across files")
grouping_tol <- config$MS1MS2_matrixGeneration_parameters$grouping_tol_losses
threshold_max_loss <- config$MS1MS2_matrixGeneration_parameters$threshold_max_loss
common_bins <- get_common_losses(all_ms2, grouping_tol)
loss_matrices <- list()
grouping_tol <- config$MS1MS2_matrixGeneration_parameters$grouping_tol_losses
threshold_max_loss <- config$MS1MS2_matrixGeneration_parameters$threshold_max_loss
common_bins <- get_common_losses(all_ms2, grouping_tol)
common_bins <- get_common_losses(all_ms1, all_ms2, grouping_tol)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('createPeakList.R')
results <- create_peaklist(peaks, config)
ms1 <- results$ms1
ms2 <- results$ms2
source('extractFragmentFeatures.R')
results <- extract_ms2_fragment_df(ms1, ms2, config)
fragment_df <- results$fragment_df
ms2 <- results$ms2
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
all_ms1 <- ms1
all_ms2 <- ms2
for (i in 1:length(all_ms2)) {
file_ms1 <- all_ms1[[i]]
file_ms2 <- all_ms2[[i]]
file_ms1.names <- as.character(file_ms1$peakID) # set row names on ms1 dataframe
file_ms2.names <- as.character(file_ms2$peakID) # set row names on ms2 dataframe
# compute the difference between each fragment peak to its parent
ms2_masses <- file_ms2$mz
parent_ids <- file_ms2$MSnParentPeakID
matches <- match(as.character(parent_ids), file_ms1.names)
parent_masses <- file_ms1[matches, 5] # column 5 is the mz
losses <- parent_masses - ms2_masses
file_ms2[, "loss"] <- losses
all_ms2[[i]] <- file_ms2
}
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(mz)), ]
common_bins <- vector()
nrow(combined_ms2)
while(nrow(combined_ms2) > 0) {
print(paste(c("binning=", nrow(combined_ms2)), collapse=""))
# get first loss value
mz <- combined_ms2$mz[1]
# calculate loss window
# should use abs() here just in case there's MS2 mz > MS1 mz
max_ppm <- abs(mz*grouping_tol*1e-06)
# match to the first unmatched peak
temp <- abs(mz-losses)
match_idx <- which(temp <= abs(max_ppm))
# calculate mean loss mz as label for ms2 row
mean_mz <- mean(combined_ms2$loss[match_idx])
common_bins <- c(common_bins, mean_mz)
# remove fragments from ms2 list and start loop again with next fragment
combined_ms2 <- combined_ms2[-match_idx,]
}
match_idx
combined_ms2
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(mz)), ]
combined_ms2
common_bins <- vector()
while(nrow(combined_ms2) > 0) {
print(paste(c("binning=", nrow(combined_ms2)), collapse=""))
# get first loss value
mz <- combined_ms2$loss[1]
# calculate loss window
# should use abs() here just in case there's MS2 mz > MS1 mz
max_ppm <- abs(mz*grouping_tol*1e-06)
# match to the first unmatched peak
temp <- abs(mz-losses)
match_idx <- which(temp <= abs(max_ppm))
# calculate mean loss mz as label for ms2 row
mean_mz <- mean(combined_ms2$loss[match_idx])
common_bins <- c(common_bins, mean_mz)
# remove fragments from ms2 list and start loop again with next fragment
combined_ms2 <- combined_ms2[-match_idx,]
}
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(mz)), ]
common_bins <- vector()
while(nrow(combined_ms2) > 0) {
print(paste(c("binning=", nrow(combined_ms2)), collapse=""))
# get first loss value
mz <- combined_ms2$loss[1]
# calculate loss window
# should use abs() here just in case there's MS2 mz > MS1 mz
max_ppm <- abs(mz*grouping_tol*1e-06)
# match to the first unmatched peak
temp <- abs(mz-losses)
match_idx <- which(temp <= abs(max_ppm))
# calculate mean loss mz as label for ms2 row
mean_mz <- mean(combined_ms2$loss[match_idx])
common_bins <- c(common_bins, mean_mz)
print(match_idx)
# remove fragments from ms2 list and start loop again with next fragment
combined_ms2 <- combined_ms2[-match_idx,]
}
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(mz)), ]
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(loss)), ]
common_bins <- vector()
while(nrow(combined_ms2) > 0) {
print(paste(c("binning=", nrow(combined_ms2)), collapse=""))
# get first loss value
mz <- combined_ms2$loss[1]
# calculate loss window
# should use abs() here just in case there's MS2 mz > MS1 mz
max_ppm <- abs(mz*grouping_tol*1e-06)
# match to the first unmatched peak
temp <- abs(mz-losses)
match_idx <- which(temp <= abs(max_ppm))
# calculate mean loss mz as label for ms2 row
mean_mz <- mean(combined_ms2$loss[match_idx])
common_bins <- c(common_bins, mean_mz)
print(match_idx)
# remove fragments from ms2 list and start loop again with next fragment
combined_ms2 <- combined_ms2[-match_idx,]
}
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(loss)), ]
common_bins <- vector()
print(paste(c("binning=", nrow(combined_ms2)), collapse=""))
mz <- combined_ms2$loss[1]
# calculate loss window
# should use abs() here just in case there's MS2 mz > MS1 mz
max_ppm <- abs(mz*grouping_tol*1e-06)
# match to the first unmatched peak
temp <- abs(mz-losses)
combined_ms2 <- do.call('rbind', all_ms2)
combined_ms2 <- combined_ms2[with(combined_ms2, order(loss)), ]
common_bins <- vector()
while(nrow(combined_ms2) > 0) {
print(paste(c("binning=", nrow(combined_ms2)), collapse=""))
# get first loss value
mz <- combined_ms2$loss[1]
# calculate loss window
# should use abs() here just in case there's MS2 mz > MS1 mz
max_ppm <- abs(mz*grouping_tol*1e-06)
# match to the first unmatched peak
temp <- abs(mz-combined_ms2$loss)
match_idx <- which(temp <= abs(max_ppm))
# calculate mean loss mz as label for ms2 row
mean_mz <- mean(combined_ms2$loss[match_idx])
common_bins <- c(common_bins, mean_mz)
print(match_idx)
# remove fragments from ms2 list and start loop again with next fragment
combined_ms2 <- combined_ms2[-match_idx,]
}
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractFragmentFeatures.R')
results <- extract_ms2_fragment_df(ms1, ms2, config)
source('extractFragmentFeatures.R')
results <- extract_ms2_fragment_df(ms1, ms2, config)
fragment_df <- results$fragment_df
ms2 <- results$ms2
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
all_ms1 <- ms1
all_ms2 <- ms2
stopifnot(length(all_ms1)==length(all_ms2))
print("Constructing common loss bins shared across files")
grouping_tol <- config$MS1MS2_matrixGeneration_parameters$grouping_tol_losses
threshold_max_loss <- config$MS1MS2_matrixGeneration_parameters$threshold_max_loss
threshold_counts <- config$MS1MS2_matrixGeneration_parameters$threshold_counts
threshold_counts <- 0
common_bins <- get_common_losses(all_ms1, all_ms2, grouping_tol, threshold_max_loss)
i <- 1
print(paste(c("Constructing loss matrix for file", i), collapse=" "))
file_ms1 <- all_ms1[[i]]
file_ms2 <- all_ms2[[i]]
ms1 <- file_ms1
ms2 <- file_ms2
# create an empty dataframe for existing words
loss_df <- data.frame(t(rep(NA,length(ms1$peakID))))
loss_df <- loss_df[-1,] # remove first column
ms1.names <- as.character(ms1$peakID) # set row names on ms1 dataframe
ms2.names <- as.character(ms2$peakID) # set row names on ms2 dataframe
copy_ms2 <- ms2
common_bins_len <- length(common_bins)
common_bins
i <- 1
mz <- common_bins[i]
word_found <- FALSE
nrow(copy_ms2)
# calculate loss mz window
max_ppm <- abs(mz*grouping_tol*1e-06)
# find losses within that window
temp <- abs(mz-copy_ms2$loss)
match_idx <- which(temp <= abs(max_ppm))
parent_id <- ms2$MSnParentPeakID[match_idx]
parent_idx <- match(as.character(parent_id), ms1.names)
if (length(parent_idx) >= threshold_counts) {
word_found <- TRUE
print(paste(c("i=", i, "/", common_bins_len,
", loss=", mz,
", remaining=", nrow(copy_ms2),
" accepted"), collapse=""))
} else {
print(paste(c("i=", i, "/", common_bins_len,
", loss=", mz,
", remaining=", nrow(copy_ms2),
" rejected"), collapse=""))
next
}
mean_mz <- round(mz, digits=5) # the bin label
word_found
match_idx
length(match_idx)
source('createPeakList.R')
results <- create_peaklist(peaks, config)
ms1 <- results$ms1
ms2 <- results$ms2
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractFragmentFeatures.R')
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
loss_df <- results$loss_df
ms2 <- results$ms2
length(loss_df)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
loss_df <- results$loss_df
ms2 <- results$ms2
loss_df[[1]]
View(loss_df[[1]])
source('createPeakList.R')
results <- create_peaklist(peaks, config)
ms1 <- results$ms1
ms2 <- results$ms2
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
View(copy_ms2)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
View(ms2)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
loss_df <- results$loss_df
ms2 <- results$ms2
View(loss_df[[1]])
sum(is.na(loss_df[[1]]))
shape(loss_df[[1]])
nrow(loss_df[[1]])
nrow(loss_df[[1]]) * ncol(loss_df[[1]])
sum(~is.na(loss_df[[1]]))
sum(!is.na(loss_df[[1]]))
source('extractLossFeatures.R')
results <- extract_neutral_loss_df(ms1, ms2, config)
